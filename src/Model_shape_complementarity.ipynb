{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import regex\n",
    "import glob\n",
    "import os\n",
    "import itertools\n",
    "from collections import namedtuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = Path(\"/data/home/arnab/abhijit/robust-surface-curvature\")\n",
    "os.chdir(\"./..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/home/arnab/abhijit/robust-surface-curvature')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sys import stderr\n",
    "from numpy import linalg\n",
    "import networkx as nx\n",
    "from scipy.spatial import Delaunay, ConvexHull\n",
    "import re\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial import ConvexHull\n",
    "#key functions\n",
    "from utils.Hypersphere import fit_hypersphere\n",
    "from utils.read_msms import read_msms\n",
    "from Bio.PDB.ResidueDepth import ResidueDepth\n",
    "from Bio.PDB.PDBParser import PDBParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_vector(x):\n",
    "    return x/np.linalg.norm(x)\n",
    "\n",
    "def unit_normal(v1, v2, v3):\n",
    "    v1, v2, v3 = np.array(v1), np.array(v2), np.array(v3)\n",
    "    v31 = v3 - v1\n",
    "    v21 = v2 - v1\n",
    "    cross = np.cross(v31/np.linalg.norm(v31), v21/np.linalg.norm(v21))\n",
    "    return cross/ np.linalg.norm(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import collections\n",
    "import regex\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from collections import OrderedDict\n",
    "import subprocess\n",
    "import unittest\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 13\n",
    "BIGGER_SIZE = 13\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it exists\n"
     ]
    }
   ],
   "source": [
    "path = Path(r\"/data/home/arnab/abhijit/robust-surface-curvature/data\")\n",
    "sub_path = Path(r\"/data/home/arnab/abhijit/robust-surface-curvature/data/Protein-inhibitor\")\n",
    "OUTPUT = \"output_protein-ligand\"\n",
    "try:\n",
    "    os.mkdir(os.path.expanduser(path/OUTPUT))\n",
    "except FileExistsError:\n",
    "    print(\"it exists\")\n",
    "# path=r\"/home/abhijit/Downloads/out_cabc.dms\"\n",
    "for files in glob.glob(sub_path.as_posix()+\"/*.dms\"):\n",
    "    filename = files\n",
    "    structure_id = regex.search(\n",
    "        r\"(?:.+[/\\\\])(.+)(?:\\.dms)\", filename).group(1)\n",
    "    s1 = structure_id\n",
    "\n",
    "    import re\n",
    "    import numpy as np\n",
    "    with open(filename, 'r') as f:\n",
    "        k = f.read()\n",
    "    pattern = re.compile(r\"(.{20,})(?:\\bA\\b)\", flags=re.M | re.I)\n",
    "    pattern2 = re.compile(r\"(.{20,})(?:\\bS\\w+\\b)(.+)\", flags=re.M)\n",
    "    l1 = pattern.findall(k)\n",
    "    l2 = pattern2.findall(k)\n",
    "    iterables1 = {}\n",
    "    iterables_orig = {}\n",
    "    iterables_normal_area = {}\n",
    "\n",
    "    for x, y in l2:\n",
    "        search = regex.search(\n",
    "            r\"(\\w{,3})\\s*(\\w+)(?:\\*?)\\s*(\\w+)(?:\\*|'?)\\s*(-?\\d+\\.\\d+)\\s*(-?\\d+\\.\\d+)\\s*(-?\\d+\\.\\d+)\", x)\n",
    "        iterables1[tuple(map(float, [search.group(4), search.group(5), search.group(6)]))] = [\n",
    "            x, list(map(float, y.split()[:]))]\n",
    "\n",
    "    for x in l1:\n",
    "        search = regex.search(\n",
    "            r\"(\\w{,3})\\s*(\\w+)(?:\\*?)\\s*(\\w+)(?:\\*|'?)\\s*(-?\\d+\\.\\d+)\\s*(-?\\d+\\.\\d+)\\s*(-?\\d+\\.\\d+)\", x)\n",
    "        iterables_orig[tuple(\n",
    "            map(float, [search.group(4), search.group(5), search.group(6)]))] = [x]\n",
    "    pattern_new = regex.compile(\n",
    "        r\"(\\w{3})\\s*(\\w+)\\s*(\\w+)\\s*(-?\\d+\\.\\d+)\\s*(-?\\d+\\.\\d+)\\s*(-?\\d+\\.\\d+)\")\n",
    "    data = np.array([x for x in iterables1.keys()])\n",
    "    data = np.array(data, 'float64')\n",
    "    Z = linkage(data, 'complete')  # ward --> complete\n",
    "    max_d = 5  # patch\n",
    "    clusters = fcluster(Z, max_d, criterion='distance')\n",
    "    curvature = collections.defaultdict(list)\n",
    "    centroid = np.median(data, axis=0)\n",
    "    with open(os.path.expanduser(path.as_posix()+'/%s/%s_%s.pdb' % (OUTPUT, s1, 'X')), 'w') as f:\n",
    "        dist = []\n",
    "        j = 0\n",
    "        for i in range(1, max(clusters)+1):\n",
    "            curv1_p = []\n",
    "            curv2_p = []\n",
    "            curv_m = fit_hypersphere(data[clusters == i])\n",
    "            ci = curv_m[1]\n",
    "            count = []\n",
    "            d_centroid = np.linalg.norm(centroid-ci)\n",
    "\n",
    "            for x in data[clusters == i]:\n",
    "\n",
    "                d = np.linalg.norm(ci-x)\n",
    "                d_c = np.linalg.norm(centroid-x)\n",
    "                if d_c > d_centroid:\n",
    "                    # if d>curv_m[0]:\n",
    "                    count.append(1)\n",
    "                    curv1_p.append(x)\n",
    "                else:\n",
    "                    count.append(-1)\n",
    "                    curv2_p.append(x)\n",
    "\n",
    "            A = (len(curv1_p)/len(data[clusters == i]))\n",
    "            B = (len(curv2_p)/len(data[clusters == i]))\n",
    "            for x in curv1_p:\n",
    "                curvature[tuple(x)] = A*100/curv_m[0]**1\n",
    "            for x in curv2_p:\n",
    "                curvature[tuple(x)] = B*-100/curv_m[0]**1  # put - sign\n",
    "\n",
    "    j = 0\n",
    "    with open(os.path.expanduser(path.as_posix()+'/%s/%s_%s.pdb' % (OUTPUT, s1, 'X')), 'w') as f:\n",
    "        for _, x in enumerate(curvature.keys()):\n",
    "\n",
    "            loc1 = iterables1[tuple(x)]\n",
    "            loc = loc1[0].split()\n",
    "            print(\"{:6s}{:5d} {:^4s}{:1s}{:3s} {:1s}{:4d}{:1s}   {:8.3f}{:8.3f}{:8.3f}{:6.2f}{:6.2f}          {:>2s}{:2s}\".format(\"ATOM\", j, \"A\", \" \", loc[0], \"X\",\n",
    "                                                                                                                                  int(loc[1].rstrip(regex.search(r'(\\d+)(.*)', loc[1]).group(2))), '', x[0], x[1], x[2], loc1[1][0],  curvature[tuple(x)], '', loc[2]), file=f)\n",
    "\n",
    "            j += 1\n",
    "\n",
    "    dist = [curvature[x] for x in curvature]\n",
    "    dist = np.array(dist)\n",
    "    dots = len(dist)\n",
    "    plt.figure()\n",
    "    plt.xlabel(\n",
    "        \"Curvature($\\kappa$)\\n$\\longleftarrow$ concave | convex $\\longrightarrow$\")\n",
    "    plt.ylabel(\"number of surface points\")\n",
    "    plt.title('%s %s:Number of surface points: %d\\nScaling factor: 100*$\\kappa$' %\n",
    "              (s1.upper(), \"\", len(dist)))\n",
    "    plt.hist(dist, bins=15, color='gray', alpha=0.8)\n",
    "    plt.savefig(os.path.expanduser(path.as_posix()+'/%s/%s_%s_%s hist.jpeg' %\n",
    "                                   (OUTPUT, dots, s1, 'X')), format='jpeg', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "\"\"\"\n",
    "Protein - Ligand\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import glob\n",
    "import regex\n",
    "import collections\n",
    "import re\n",
    "import copy\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 13\n",
    "BIGGER_SIZE = 13\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "sub_path = Path(r\"/data/home/arnab/abhijit/robust-surface-curvature/data/Protein-inhibitor\")\n",
    "\n",
    "pdb_id = collections.defaultdict(list)\n",
    "dms_id = collections.defaultdict(list)\n",
    "dms_path = os.path.expanduser(sub_path.as_posix()+\"/*.dms\")\n",
    "\n",
    "for files in glob.glob(dms_path):\n",
    "    filename = files\n",
    "    structure_id = regex.search(\n",
    "        r\"(?:.+[/\\\\])(.+)(?:\\.dms)\", filename, flags=regex.I).group(1)\n",
    "    s1 = structure_id\n",
    "    dms_id[structure_id].append(filename)\n",
    "\n",
    "dms_normal = {}\n",
    "for name_dms in dms_id:\n",
    "    with open(dms_id[name_dms][0], 'r') as f:\n",
    "        k = f.read()\n",
    "    pattern = re.compile(r\"(.{20,})(?:\\bA\\b)\", flags=re.M | re.I)\n",
    "    pattern2 = re.compile(r\"(.{20,})(?:\\bS\\w+\\b)(.+)\", flags=re.M)\n",
    "    l1 = pattern.findall(k)\n",
    "    l2 = pattern2.findall(k)\n",
    "    iterables1 = {}\n",
    "    iterables_orig = {}\n",
    "    iterables_normal_area = {}\n",
    "    for x, y in l2:\n",
    "        search = regex.search(\n",
    "            r\"(\\w{,3})\\s*(\\w+)(?:\\*?)\\s*(\\w+)(?:\\*|'?)\\s*(-?\\d+\\.\\d+)\\s*(-?\\d+\\.\\d+)\\s*(-?\\d+\\.\\d+)\", x)\n",
    "        iterables1[tuple(map(float, [search.group(4), search.group(\n",
    "            5), search.group(6)]))] = list(map(float, y.split()[1:]))\n",
    "    dms_normal[name_dms] = copy.deepcopy(iterables1)\n",
    "\n",
    "for files in glob.glob((path/OUTPUT).as_posix()+\"/*.pdb\"):\n",
    "    filename = files\n",
    "    structure_id = regex.search(\n",
    "        r\"(?:.+/)(.{4})(?:.*_X\\.pdb)\", filename).group(1)\n",
    "    pdb_id[structure_id].append(filename)\n",
    "\n",
    "\n",
    "for name_pdb in pdb_id:\n",
    "    for i in itertools.combinations(pdb_id[name_pdb], 2):\n",
    "        with open(i[0], 'r') as f:\n",
    "            k = f.readlines()\n",
    "        iterables = {}\n",
    "        arr1 = []\n",
    "        arr1_norm = []\n",
    "        if(regex.search(r\"_lig_X\", i[0])):\n",
    "            suffix = \"_lig\"\n",
    "        else:\n",
    "            suffix = \"\"\n",
    "        for x in k:\n",
    "            iterables.setdefault(x[60:66].replace(\" \", \"\"), []).append(list\n",
    "                                                                       (map(float, [x[30:38].replace(\" \", \"\"),\n",
    "                                                                                    x[38:46].replace(\n",
    "                                                                                        \" \", \"\"),\n",
    "                                                                                    x[46:54].replace(\" \", \"\")])))\n",
    "            arr1.append(list(map(float, [x[30:38].replace(\" \", \"\"),\n",
    "                                         x[38:46].replace(\" \", \"\"),\n",
    "                                         x[46:54].replace(\" \", \"\"), x[60:66].replace(\" \", \"\")])))\n",
    "            arr1_norm.append(dms_normal[name_pdb+suffix][tuple(map(float, [x[30:38].replace(\" \", \"\"),\n",
    "                                                                           x[38:46].replace(\n",
    "                                                                               \" \", \"\"),\n",
    "                                                                           x[46:54].replace(\" \", \"\")]))])\n",
    "        with open(i[1], 'r') as f:\n",
    "            k1 = f.readlines()\n",
    "\n",
    "        iterables1 = {}\n",
    "        arr2 = []\n",
    "        arr2_norm = []\n",
    "        if(regex.search(r\"_lig_X\", i[1])):\n",
    "            suffix = \"_lig\"\n",
    "        else:\n",
    "            suffix = \"\"\n",
    "        for x in k1:\n",
    "            iterables1.setdefault(x[60:66].replace(\" \", \"\"), []).append(list\n",
    "                                                                        (map(float, [x[30:38].replace(\" \", \"\"),\n",
    "                                                                                     x[38:46].replace(\n",
    "                                                                                         \" \", \"\"),\n",
    "                                                                                     x[46:54].replace(\" \", \"\")])))\n",
    "            arr2.append(list(map(float, [x[30:38].replace(\" \", \"\"),\n",
    "                                         x[38:46].replace(\" \", \"\"),\n",
    "                                         x[46:54].replace(\" \", \"\"), x[60:66].replace(\" \", \"\")])))\n",
    "            arr2_norm.append(dms_normal[name_pdb+suffix][tuple(map(float, [x[30:38].replace(\" \", \"\"),\n",
    "                                                                           x[38:46].replace(\n",
    "                                                                               \" \", \"\"),\n",
    "                                                                           x[46:54].replace(\" \", \"\")]))])\n",
    "        arr1 = np.array(arr1)\n",
    "        arr2 = np.array(arr2)\n",
    "        arr1_norm = np.array(arr1_norm)\n",
    "        arr2_norm = np.array(arr2_norm)\n",
    "        normal_product = np.dot(arr2_norm, arr1_norm.T)\n",
    "\n",
    "        arr_dist = distance.cdist(\n",
    "            arr2[:, (0, 1, 2)], arr1[:, (0, 1, 2)], 'euclidean')\n",
    "\n",
    "        new_dist = np.exp(-1*(arr_dist-np.mean(arr_dist, axis=0))\n",
    "                          ** 2/(2*np.var(arr_dist, axis=0)))\n",
    "\n",
    "        new_curv = distance.cdist(arr2[:, (3,)], -1*arr1[:, (3,)], 'cityblock')\n",
    "        dat_new = (np.multiply(new_curv, new_dist)).flatten()\n",
    "        plt.figure(dpi=300)\n",
    "\n",
    "        plt.xlabel(\"shape complementarity\")\n",
    "        plt.ylabel(\"Number density\")\n",
    "        plt.hist(dat_new, bins=20, density=True, color='gray', alpha=0.8)\n",
    "        plt.title(\"%s_%s\" % (name_pdb, \"_lig\"))\n",
    "        plt.show()\n",
    "        plt.savefig(path.as_posix()+\"/%s_%s_plot.jpeg\" %\n",
    "                    (name_pdb, \"_lig\"), format='jpeg', dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
